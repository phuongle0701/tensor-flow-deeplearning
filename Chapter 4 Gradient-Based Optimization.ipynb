{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Based Optimization\n",
    "\n",
    "\n",
    "* The steepest descent proposes a new point (gradient descent) \n",
    "\n",
    "\n",
    "$$\n",
    "x'= x - \\epsilon \\nabla_{x} f(x)\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is the learning rate, a positive scalar determining the size of the step. We can choose $\\epsilon$ in several different ways. \n",
    "\n",
    "* Another approach to set $\\epsilon$ is to evaluate $f(x - \\epsilon \\nabla_{x} f(x))$ for several values of $\\epsilon$ and choose the one that results in the smallest objective function value - This is known as line search method.  \n",
    "\n",
    "* Convergence: steepest descent method converges when every element of the gradient is zero (or, in practive very close to zero). In some cases, we may be able to avoid running this iterative algorithm, and jump directly to the critical point by solving the equation $\\nabla_{x} f(x) = 0$ for $x$.\n",
    "\n",
    "\n",
    "* We consider the function $f(x) = (x+10)ˆ{2}$\n",
    "\n",
    "* Step 1: We initialize the value $x  = 0$ and find the gradient value as $x = 0$ which is $f'(x) = 20$\n",
    "\n",
    "* Step 2: We specify the learning rate $\\epsilon = 0.0001$ and perform the iteration: \n",
    "\n",
    "$$\n",
    "x_{n+1} = x_{n} - \\epsilon \\times f'(x_{n}) = x_{n} - 0.0001 \\times f'(x_{n})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local minimum value is:  -9.999999951880648\n"
     ]
    }
   ],
   "source": [
    "## Specify the learning rate \n",
    "learn_rate = 0.01\n",
    "\n",
    "derf = lambda x: 2*(x + 10) \n",
    "\n",
    "## Specify some values:\n",
    "precision = 0.000000001\n",
    "iter_count = 0\n",
    "max_iteration = 100000000\n",
    "cur_x = 0\n",
    "prev_step_size = 1\n",
    "\n",
    "while prev_step_size > precision and iter_count < max_iteration: \n",
    "    prev_x = cur_x \n",
    "    cur_x = cur_x - learn_rate * derf(prev_x)\n",
    "    prev_step_size = abs(cur_x - prev_x)\n",
    "    iter_count +=1\n",
    "    #print(\"Iterations \", iter_count, \"\\nX value \", cur_x)\n",
    "\n",
    "print(\"The local minimum value is: \", cur_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using the method of steepest descent the local minimum value of $f(x) = (x+10)ˆ{2}$ is found to be $-9.999999951880648$. Theoretically, if we solve the function and apply the method theoritically, it is $-10$. \n",
    "\n",
    "\n",
    "* Now we consider another function: $f(x) = (xˆ{2} - 10)ˆ{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local minimum value is\n",
      " 3.1359958525475453\n"
     ]
    }
   ],
   "source": [
    "## specify the learn rate: \n",
    "\n",
    "learn_rate = 0.0001\n",
    " \n",
    "derf = lambda x: 6*(x*x - 10)\n",
    "\n",
    "## specify the precision: \n",
    "precision = 0.0001 ## round to 3 decimals\n",
    "iter_count = 0\n",
    "max_iter = 100000\n",
    "\n",
    "cur_x = -2\n",
    "prevstep_size = 1\n",
    "\n",
    "### The convergence: |x_{n+1} - x_{n} | < tolerance (precision)\n",
    "\n",
    "while prevstep_size > precision and iter_count < max_iter: \n",
    "    prev_x = cur_x \n",
    "    cur_x = cur_x - learn_rate*derf(prev_x) \n",
    "    prevstep_size = abs(cur_x - prev_x)\n",
    "    iter_count = iter_count + 1\n",
    "    \n",
    "print(\"The local minimum value is\\n\", cur_x)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
